{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Mod 5 Project - Sandy's Notebook"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports and Data Ingestion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import libraries\n",
    "\n",
    "import mod_5_project_helper as hp\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import KFold, cross_validate\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.tree import export_graphviz\n",
    "\n",
    "\n",
    "#set environment - REMEMBER TO COPY OVER mod_5_project_helper.py\n",
    "\n",
    "hp.set_environment()\n",
    "%matplotlib inline\n",
    "pd.set_option('display.max_columns', None)\n",
    "# pd.set_option('display.max_rows', None)\n",
    "\n",
    "#initiliase variables\n",
    "\n",
    "%run variables.py\n",
    "\n",
    "#import data\n",
    "\n",
    "df = pd.read_csv(\"data.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Cleanup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop_duplicates(inplace = True) #drop 10,728 duplicate rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop(index = 100000, axis = 0, inplace = True) #delete last blank row in the data set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop(df[df[\"Current Loan Amount\"] == 99999999].index, inplace = True) #delete 11484 rows where the loan amount is 99999999"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.dropna(subset = ['Credit Score'], inplace = True) #delete 19154 rows where Credit Score is missing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.dropna(subset = ['Years in current job'], inplace = True) #delete 2564 rows where Years in current job is missing "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"Years in current job\"].replace(to_replace = \"year.*\", value = \"\",inplace = True, regex = True) #remove 'years' or 'year' from string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop(df[df[\"Home Ownership\"] == \"HaveMortgage\"].index, inplace = True) #delete 120 rows with \"HaveMortgage\" as meaning isn't clear"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.dropna(subset = ['Months since last delinquent'], inplace = True) #delete 30,000 rows where data is missing "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop(columns = \"Maximum Open Credit\", inplace = True) #delete Maximum Open Credit columns as some of these numbers are huge e.g. 798255370.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = hp.drop_column_keyword_search(df, [\"Loan ID\", \"Customer ID\"]) #delete features 'Loan ID' and 'Customer ID' as they don't add anything"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.fillna(df.median()) #fill remaining values with "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "#rename and consolidate categorical variables for purpose\n",
    "\n",
    "df[\"Purpose\"].replace({\n",
    "              \"Business Loan\": \"business_loan\",\n",
    "              \"Medical Bills\": \"medical bills\",\n",
    "              \"Educational Expenses\": \"educational_expenses\",\n",
    "              \"Buy House\": \"buy_house\",\n",
    "              \"Buy a Car\": \"buy_a_car\",\n",
    "              \"Debt Consolidation\": \"debt_consolidation\",\n",
    "              \"Home Improvements\": \"home_improvements\",\n",
    "              \"Take a Trip\": \"take_a_trip\",\n",
    "              \"vacation\": \"take_a_trip\",\n",
    "              \"Major Purchase\": \"other\",\n",
    "              \"Other\": \"other\", \n",
    "              \"renewable_energy\": \"home_improvements\",\n",
    "              \"small_business\": \"business_loan\",\n",
    "              \"moving\": \"home_improvements\",\n",
    "              \"major_purchase\": \"major_purchase\",\n",
    "              \"wedding\": \"wedding\"\n",
    "              }, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "#rename categorical variables for Home Ownership\n",
    "\n",
    "df[\"Home Ownership\"].replace({\n",
    "              \"Home Mortgage\": \"mortgage\",\n",
    "              \"Rent\": \"rent\",\n",
    "              \"Own Home\": \"own_home\",\n",
    "              }, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "#rename categorical variables for Term\n",
    "\n",
    "df[\"Term\"].replace({\n",
    "              \"Long Term\": \"long_term\",\n",
    "              \"Short Term\": \"short_term\",\n",
    "              }, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "#rename categorical variables for Loan Status\n",
    "\n",
    "df[\"Loan Status\"].replace({\n",
    "              \"Fully Paid\": \"fully_paid\",\n",
    "              \"Charged Off\": \"default\",\n",
    "              }, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "#rename columns to make the dataset easier to work with using . notation\n",
    "\n",
    "df.columns = ['loan_status',\n",
    "              'loan_amount',\n",
    "              'term',\n",
    "              'credit_score',\n",
    "              'annual_income',\n",
    "              'years_in_current_job',\n",
    "              'home_ownership',\n",
    "              'loan_purpose',\n",
    "              'monthly_debt',\n",
    "              'years_of_credit_history',\n",
    "              'months_since_last_delinquent',\n",
    "              'number_of_open_accounts',\n",
    "              'number_of_credit_problems',\n",
    "              'current_credit_balance',\n",
    "              'bankruptcies',\n",
    "              'tax_liens']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.reset_index(inplace = True); #reset index"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cleaned Dataset Information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train, test split, sampling and K-folds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "default_df = df[df.loan_status == \"default\"] #create a new dataframe of loan defaulters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "fully_paid_df = df[df.loan_status == \"fully_paid\"] #create a new dataframe of fully paid loans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "fully_paid_sample = fully_paid_df.sample(7479,random_state = 42) #sample the fully paid loans dataframe to a number equal to the default loan dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "update_df = pd.concat([default_df, fully_paid_sample]) #create a new dataframe with a 50/50 split of defaulters and paid loans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "update_df = update_df.sample(frac = 1, random_state = 42) #shuffle the new 50/50 split dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = update_df.drop(columns = \"loan_status\") #create predictor dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = update_df.loan_status #create target variable dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42) #create train/test split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "crossvalidation = KFold(n_splits=10, shuffle=True, random_state=42) #initialise cross validation object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export data for CSVs for ease\n",
    "\n",
    "X_train.to_csv(\"X_train.csv\")\n",
    "X_test.to_csv(\"X_test.csv\")\n",
    "y_train.to_csv(\"y_train.csv\")\n",
    "y_test.to_csv(\"y_test.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Decision Trees"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.reset_index(inplace = True); #reset index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.drop(columns = [\"level_0\", \"index\"], inplace = True); #drop old index columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "#make a dataframe of categorical variables\n",
    "\n",
    "X_train_categorical = pd.concat([X_train.term, \n",
    "                                 X_train.years_in_current_job, \n",
    "                                 X_train.home_ownership, \n",
    "                                 X_train.loan_purpose], \n",
    "                                 axis = 1) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "#make a dataframe of continous variables\n",
    "\n",
    "X_train_continuous = pd.concat([X_train.loan_amount, \n",
    "                                X_train.credit_score, \n",
    "                                X_train.annual_income, \n",
    "                                X_train.monthly_debt, \n",
    "                                X_train.years_of_credit_history,\n",
    "                                X_train.months_since_last_delinquent,\n",
    "                                X_train.number_of_open_accounts,\n",
    "                                X_train.current_credit_balance,\n",
    "                                X_train.bankruptcies,\n",
    "                                X_train.tax_liens], \n",
    "                                axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "#one hot encode categorical variables\n",
    "#for everything but decision trees we should do drop_first = True\n",
    "X_train_one_hot_encoded = pd.get_dummies(X_train_categorical)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "#stitch the one hot encoded dataframe back together\n",
    "\n",
    "X_train_updated = pd.concat([X_train_continuous, X_train_one_hot_encoded], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "#instantiate tree classifier object\n",
    "\n",
    "tree_clf = DecisionTreeClassifier(max_depth = 3, min_samples_leaf = 10, random_state = 42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'fit_time': array([0.07398486, 0.11715627, 0.04394221, 0.04320502, 0.0436821 ,\n",
       "        0.04249501, 0.04287291, 0.04225779, 0.04144883, 0.04249907]),\n",
       " 'score_time': array([0.03874898, 0.00412798, 0.00360513, 0.00337505, 0.00368381,\n",
       "        0.00361395, 0.00359797, 0.00337315, 0.00354314, 0.00359797]),\n",
       " 'test_score': array([0.64828739, 0.66081871, 0.62238931, 0.65998329, 0.64076859,\n",
       "        0.65079365, 0.65802676, 0.64214047, 0.63795987, 0.6312709 ]),\n",
       " 'train_score': array([0.6557712 , 0.65196397, 0.65753552, 0.65270684, 0.65623549,\n",
       "        0.6557712 , 0.65431755, 0.65673166, 0.65719591, 0.65524605])}"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#fit model using cross validation. Need to check this to make sure the approach is accurate and use ROC curve\n",
    "#with hyperparamter tuning\n",
    "\n",
    "baseline_model = cross_validate(tree_clf, \n",
    "                                X_train_updated, \n",
    "                                y_train, \n",
    "                                cv=crossvalidation, \n",
    "                                return_train_score = True)\n",
    "\n",
    "baseline_model\n",
    "\n",
    "#tree_clf.fit(X_train_updated,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export tree to a dot file so it can be converted to an image using the CLI:\n",
    "# dot -Tpng tree.dot -o tree.png\n",
    "\n",
    "export_graphviz(tree_clf, \n",
    "                out_file = (\"tree.dot\"), \n",
    "                feature_names = X_train_updated.columns, \n",
    "                class_names = y_train.values, \n",
    "                rounded = True, \n",
    "                filled = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:learn-env] *",
   "language": "python",
   "name": "conda-env-learn-env-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
