{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Mod 5 Project - Sandy's Notebook"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports and Data Ingestion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import libraries\n",
    "\n",
    "import mod_5_project_helper as hp\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.tree import export_graphviz\n",
    "\n",
    "\n",
    "#set environment - REMEMBER TO COPY OVER mod_5_project_helper.py\n",
    "\n",
    "hp.set_environment()\n",
    "%matplotlib inline\n",
    "pd.set_option('display.max_columns', None)\n",
    "# pd.set_option('display.max_rows', None)\n",
    "\n",
    "#initiliase variables\n",
    "\n",
    "%run variables.py\n",
    "\n",
    "#import data\n",
    "\n",
    "df = pd.read_csv(\"data.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Cleanup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop_duplicates(inplace = True) #drop 10,728 duplicate rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop(index = 100000, axis = 0, inplace = True) #delete last blank row in the data set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop(df[df[\"Current Loan Amount\"] == 99999999].index, inplace = True) #delete 11484 rows where the loan amount is 99999999"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.dropna(subset = ['Credit Score'], inplace = True) #delete 19154 rows where Credit Score is missing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.dropna(subset = ['Years in current job'], inplace = True) #delete 2564 rows where Years in current job is missing "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"Years in current job\"].replace(to_replace = \"year.*\", value = \"\",inplace = True, regex = True) #remove 'years' or 'year' from string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop(df[df[\"Home Ownership\"] == \"HaveMortgage\"].index, inplace = True) #delete 120 rows with \"HaveMortgage\" as meaning isn't clear"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.dropna(subset = ['Months since last delinquent'], inplace = True) #delete 30,000 rows where data is missing "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop(columns = \"Maximum Open Credit\", inplace = True) #delete Maximum Open Credit columns as some of these numbers are huge e.g. 798255370.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = hp.drop_column_keyword_search(df, [\"Loan ID\", \"Customer ID\"]) #delete features 'Loan ID' and 'Customer ID' as they don't add anything"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.fillna(df.median()) #fill remaining values with "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#rename and consolidate categorical variables for purpose\n",
    "\n",
    "df[\"Purpose\"].replace({\n",
    "              \"Business Loan\": \"business_loan\",\n",
    "              \"Medical Bills\": \"medical bills\",\n",
    "              \"Educational Expenses\": \"educational_expenses\",\n",
    "              \"Buy House\": \"buy_house\",\n",
    "              \"Buy a Car\": \"buy_a_car\",\n",
    "              \"Debt Consolidation\": \"debt_consolidation\",\n",
    "              \"Home Improvements\": \"home_improvements\",\n",
    "              \"Take a Trip\": \"take_a_trip\",\n",
    "              \"vacation\": \"take_a_trip\",\n",
    "              \"Major Purchase\": \"other\",\n",
    "              \"Other\": \"other\", \n",
    "              \"renewable_energy\": \"home_improvements\",\n",
    "              \"small_business\": \"business_loan\",\n",
    "              \"moving\": \"home_improvements\",\n",
    "              \"major_purchase\": \"major_purchase\",\n",
    "              \"wedding\": \"wedding\"\n",
    "              }, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#rename categorical variables for Home Ownership\n",
    "\n",
    "df[\"Home Ownership\"].replace({\n",
    "              \"Home Mortgage\": \"mortgage\",\n",
    "              \"Rent\": \"rent\",\n",
    "              \"Own Home\": \"own_home\",\n",
    "              }, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#rename categorical variables for Term\n",
    "\n",
    "df[\"Term\"].replace({\n",
    "              \"Long Term\": \"long_term\",\n",
    "              \"Short Term\": \"short_term\",\n",
    "              }, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#rename categorical variables for Loan Status\n",
    "\n",
    "df[\"Loan Status\"].replace({\n",
    "              \"Fully Paid\": \"fully_paid\",\n",
    "              \"Charged Off\": \"default\",\n",
    "              }, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#rename columns to make the dataset easier to work with using . notation\n",
    "\n",
    "df.columns = ['loan_status',\n",
    "              'loan_amount',\n",
    "              'term',\n",
    "              'credit_score',\n",
    "              'annual_income',\n",
    "              'years_in_current_job',\n",
    "              'home_ownership',\n",
    "              'loan_purpose',\n",
    "              'monthly_debt',\n",
    "              'years_of_credit_history',\n",
    "              'months_since_last_delinquent',\n",
    "              'number_of_open_accounts',\n",
    "              'number_of_credit_problems',\n",
    "              'current_credit_balance',\n",
    "              'bankruptcies',\n",
    "              'tax_liens']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.reset_index(inplace = True); #reset index"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cleaned Dataset Information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train, test split, sampling and K-folds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "default_df = df[df.loan_status == \"default\"] #create a new dataframe of loan defaulters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "fully_paid_df = df[df.loan_status == \"fully_paid\"] #create a new dataframe of fully paid loans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "fully_paid_sample = fully_paid_df.sample(7479,random_state = 42) #sample the fully paid loans dataframe to a number equal to the default loan dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "update_df = pd.concat([default_df, fully_paid_sample]) #create a new dataframe with a 50/50 split of defaulters and paid loans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "update_df = update_df.sample(frac = 1, random_state = 42) #shuffle the new 50/50 split dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = update_df.drop(columns = \"loan_status\") #create predictor dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = update_df.loan_status #create target variable dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42) #create train/test split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "crossvalidation = KFold(n_splits=10, shuffle=True, random_state=42) #initialise cross validation object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export data for CSVs for ease\n",
    "\n",
    "X_train.to_csv(\"X_train.csv\")\n",
    "X_test.to_csv(\"X_test.csv\")\n",
    "y_train.to_csv(\"y_train.csv\")\n",
    "y_test.to_csv(\"y_test.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Decision Trees"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.reset_index(inplace = True); #reset index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.drop(columns = [\"level_0\", \"index\"], inplace = True); #drop old index columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "#make a dataframe of categorical variables\n",
    "\n",
    "X_train_categorical = pd.concat([X_train.term, \n",
    "                                 X_train.years_in_current_job, \n",
    "                                 X_train.home_ownership, \n",
    "                                 X_train.loan_purpose], \n",
    "                                 axis = 1) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "#make a dataframe of continous variables\n",
    "\n",
    "X_train_continuous = pd.concat([X_train.loan_amount, \n",
    "                                X_train.credit_score, \n",
    "                                X_train.annual_income, \n",
    "                                X_train.monthly_debt, \n",
    "                                X_train.years_of_credit_history,\n",
    "                                X_train.months_since_last_delinquent,\n",
    "                                X_train.number_of_open_accounts,\n",
    "                                X_train.current_credit_balance,\n",
    "                                X_train.bankruptcies,\n",
    "                                X_train.tax_liens], \n",
    "                                axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "#one hot encode categorical variables\n",
    "#for everything but decision trees we should do drop_first = True\n",
    "X_train_one_hot_encoded = pd.get_dummies(X_train_categorical)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "#stitch the one hot encoded dataframe back together\n",
    "\n",
    "X_train_updated = pd.concat([X_train_continuous, X_train_one_hot_encoded], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "#instantiate tree classifier object\n",
    "\n",
    "tree_clf = DecisionTreeClassifier(max_depth = 3, min_samples_leaf = 10, random_state = 42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',\n",
       "                       max_depth=3, max_features=None, max_leaf_nodes=None,\n",
       "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "                       min_samples_leaf=10, min_samples_split=2,\n",
       "                       min_weight_fraction_leaf=0.0, presort='deprecated',\n",
       "                       random_state=42, splitter='best')"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#fit model\n",
    "\n",
    "tree_clf.fit(X_train_updated,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export tree to a dot file so it can be converted to an image using the CLI:\n",
    "# dot -Tpng tree.dot -o tree.png\n",
    "\n",
    "export_graphviz(tree_clf, \n",
    "                out_file = (\"tree.dot\"), \n",
    "                feature_names = X_train_updated.columns, \n",
    "                class_names = y_train.values, \n",
    "                rounded = True, \n",
    "                filled = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:learn-env] *",
   "language": "python",
   "name": "conda-env-learn-env-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
